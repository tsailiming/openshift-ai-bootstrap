{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Compressor Workbench -- Getting Started\n",
    "\n",
    "This notebook will demonstrate how common [LLM Compressor](https://github.com/vllm-project/llm-compressor) flows can be run on the [opendatahub/llmcompressor-workbench](https://quay.io/repository/opendatahub/llmcompressor-workbench) image.\n",
    "\n",
    "We will show how a user can compress and evaluate a Large Language Model, first without data and then with a calibration dataset.\n",
    "\n",
    "The notebook will detect if a GPU is available. If one is not available, it will demonstrate an abbreviated run, so users without GPU access can still get a feel for `llm-compressor`.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> If you are not using the Workbench image, just be sure to have lm_eval>=0.4.8 and llmcompressor>=0.5.1 installed\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\\) Data-Free Model Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmcompressor.modifiers.quantization import QuantizationModifier\n",
    "\n",
    "# model to compress\n",
    "model_id = \"Qwen/Qwen2.5-7B-Instruct\" #\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "# This recipe will quantize all Linear layers except those in the `lm_head`,\n",
    "#  which is often sensitive to quantization. The W4A16 scheme compresses\n",
    "#  weights to 4-bit integers while retaining 16-bit activations.\n",
    "recipe = QuantizationModifier(\n",
    "    targets=\"Linear\", scheme=\"W4A16\", ignore=[\"lm_head\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8617cb534dd47ee841852ca41539429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load up model using huggingface API\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, device_map=\"auto\", torch_dtype=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-13 07:20:17 [importing.py:53] Triton module has been replaced with a placeholder.\n",
      "INFO 09-13 07:20:18 [__init__.py:239] Automatically detected platform cuda.\n",
      "INFO 09-13 07:20:28 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'score', 'reward', 'generate'}. Defaulting to 'generate'.\n",
      "INFO 09-13 07:20:28 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/llmcompressor/pytorch/__init__.py:19: UserWarning: torch.compile is not supported by llmcompressor for torch 2.0.x\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 09-13 07:20:29 [utils.py:2382] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/getting_started/troubleshooting.html#python-multiprocessing for more information. Reason: CUDA is initialized\n",
      "INFO 09-13 07:20:33 [__init__.py:239] Automatically detected platform cuda.\n",
      "INFO 09-13 07:20:36 [core.py:58] Initializing a V1 LLM engine (v0.8.5) with config: model='Qwen/Qwen2.5-7B-Instruct', speculative_config=None, tokenizer='Qwen/Qwen2.5-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=1234, served_model_name=Qwen/Qwen2.5-7B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 09-13 07:20:36 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f497cb17e90>\n",
      "INFO 09-13 07:20:36 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 09-13 07:20:36 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "WARNING 09-13 07:20:36 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 09-13 07:20:36 [gpu_model_runner.py:1329] Starting to load model Qwen/Qwen2.5-7B-Instruct...\n",
      "INFO 09-13 07:20:37 [weight_utils.py:265] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  2.30it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:00<00:00,  2.01it/s]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.94it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.97it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.99it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-13 07:20:39 [loader.py:458] Loading weights took 2.11 seconds\n",
      "INFO 09-13 07:20:40 [gpu_model_runner.py:1347] Model loading took 14.2488 GiB and 2.948042 seconds\n",
      "INFO 09-13 07:20:46 [backends.py:420] Using cache directory: /opt/app-root/src/.cache/vllm/torch_compile_cache/ab94994109/rank_0_0 for vLLM's torch.compile\n",
      "INFO 09-13 07:20:46 [backends.py:430] Dynamo bytecode transform time: 6.50 s\n",
      "INFO 09-13 07:20:52 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 5.035 s\n",
      "INFO 09-13 07:20:53 [monitor.py:33] torch.compile takes 6.50 s in total\n",
      "INFO 09-13 07:20:54 [kv_cache_utils.py:634] GPU KV cache size: 170,384 tokens\n",
      "INFO 09-13 07:20:54 [kv_cache_utils.py:637] Maximum concurrency for 32,768 tokens per request: 5.20x\n",
      "INFO 09-13 07:21:16 [gpu_model_runner.py:1686] Graph capturing finished in 22 secs, took 0.45 GiB\n",
      "INFO 09-13 07:21:16 [core.py:159] init engine (profile, create kv cache, warmup model) took 36.62 seconds\n",
      "INFO 09-13 07:21:16 [core_client.py:439] Core engine process 0 ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-09-13 07:21:32] INFO task.py:420: Building contexts for gsm8k on rank 0...\n",
      "100%|██████████| 1319/1319 [00:03<00:00, 356.49it/s]\n",
      "[2025-09-13 07:21:36] INFO evaluator.py:517: Running generate_until requests\n",
      "Running generate_until requests:   0%|          | 0/1319 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269bf0b54804447bbf0255612db02bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1319 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running generate_until requests: 100%|██████████| 1319/1319 [02:48<00:00,  7.82it/s] \n",
      "[rank0]:[W913 07:24:28.305679527 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "import lm_eval\n",
    "from lm_eval.utils import make_table\n",
    "\n",
    "results_baseline = lm_eval.simple_evaluate(\n",
    "    model=\"vllm\" if use_gpu else \"hf\",\n",
    "    model_args={\n",
    "        \"pretrained\": model_id,\n",
    "        \"add_bos_token\": True,\n",
    "        \"device\": \"auto\"\n",
    "    },\n",
    "    tasks=[\"gsm8k\"],\n",
    "    batch_size=\"auto\" if use_gpu else 4,\n",
    "    limit=None if use_gpu else 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Tasks|Version|     Filter     |n-shot|  Metric   |   |Value |   |Stderr|\n",
      "|-----|------:|----------------|-----:|-----------|---|-----:|---|-----:|\n",
      "|gsm8k|      3|flexible-extract|     5|exact_match|↑  |0.8385|±  |0.0101|\n",
      "|     |       |strict-match    |     5|exact_match|↑  |0.8089|±  |0.0108|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_table(results_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:24:29.943238+0000 | reset | INFO - Compression lifecycle reset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging all LLM Compressor modifier-level logs to sparse_logs/13-09-2025_07.24.29.log\n",
      "[2025-09-13 07:24:29] INFO logger.py:391: Logging all LLM Compressor modifier-level logs to sparse_logs/13-09-2025_07.24.29.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:24:29.946181+0000 | from_modifiers | INFO - Creating recipe from modifiers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manager stage: Modifiers initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:24:32.686849+0000 | initialize | INFO - Compression lifecycle initialized for 1 modifiers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manager stage: Modifiers finalized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:24:32.688037+0000 | finalize | INFO - Compression lifecycle finalized for 1 modifiers\n",
      "2025-09-13T07:24:32.688517+0000 | post_process | WARNING - Optimized model is not saved. To save, please provide`output_dir` as input arg.Ex. `oneshot(..., output_dir=...)`\n"
     ]
    }
   ],
   "source": [
    "# Run compression using `oneshot`\n",
    "from llmcompressor import oneshot\n",
    "\n",
    "model = oneshot(model=model, recipe=recipe, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:24:32.692386+0000 | save_pretrained_wrapper | INFO - Fetching state_dict - this may take some time\n",
      "2025-09-13T07:24:51.999153+0000 | save_pretrained_wrapper | INFO - Fetching compressor\n",
      "2025-09-13T07:24:51.999899+0000 | get_model_compressor | INFO - skip_sparsity_compression_stats set to True. Skipping sparsity compression statistic calculations. No sparsity compressor will be applied.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Quantized Compression: 100%|██████████| 731/731 [00:42<00:00, 17.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:25:34.013183+0000 | save_pretrained_wrapper | INFO - Saving compressed model to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Save model and tokenizer\n",
    "model_dir = \"./\" + model_id.split(\"/\")[-1] + \"-W4A16\"\n",
    "model.save_pretrained(model_dir)\n",
    "tokenizer.save_pretrained(model_dir);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2\\) Evaluate compressed model using open-source `lm_eval` framework\n",
    "\n",
    "We will evaluate the performance of the model on the [`wikitext`](https://paperswithcode.com/dataset/wikitext-2) language modeling dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-09-13 07:26:03] INFO evaluator.py:169: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "[2025-09-13 07:26:03] INFO evaluator.py:193: Initializing vllm model, with arguments: {'pretrained': './Qwen2.5-7B-Instruct-W4A16', 'add_bos_token': True, 'device': 'auto'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-13 07:26:03 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'score', 'reward', 'generate'}. Defaulting to 'generate'.\n",
      "INFO 09-13 07:26:03 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/llmcompressor/pytorch/__init__.py:19: UserWarning: torch.compile is not supported by llmcompressor for torch 2.0.x\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-13 07:26:07 [__init__.py:239] Automatically detected platform cuda.\n",
      "INFO 09-13 07:26:10 [core.py:58] Initializing a V1 LLM engine (v0.8.5) with config: model='./Qwen2.5-7B-Instruct-W4A16', speculative_config=None, tokenizer='./Qwen2.5-7B-Instruct-W4A16', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=compressed-tensors, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=1234, served_model_name=./Qwen2.5-7B-Instruct-W4A16, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 09-13 07:26:10 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fc6bde69250>\n",
      "INFO 09-13 07:26:10 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 09-13 07:26:10 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "WARNING 09-13 07:26:10 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 09-13 07:26:10 [gpu_model_runner.py:1329] Starting to load model ./Qwen2.5-7B-Instruct-W4A16...\n",
      "INFO 09-13 07:26:10 [compressed_tensors_wNa16.py:94] Using MarlinLinearKernel for CompressedTensorsWNA16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  7.26it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.28it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.54it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-13 07:26:11 [loader.py:458] Loading weights took 0.91 seconds\n",
      "WARNING 09-13 07:26:12 [kv_cache.py:128] Using Q scale 1.0 and prob scale 1.0 with fp8 attention. This may cause accuracy issues. Please make sure Q/prob scaling factors are available in the fp8 checkpoint.\n",
      "INFO 09-13 07:26:12 [gpu_model_runner.py:1347] Model loading took 5.1816 GiB and 1.158507 seconds\n",
      "INFO 09-13 07:26:20 [backends.py:420] Using cache directory: /opt/app-root/src/.cache/vllm/torch_compile_cache/9b199998ee/rank_0_0 for vLLM's torch.compile\n",
      "INFO 09-13 07:26:20 [backends.py:430] Dynamo bytecode transform time: 8.46 s\n",
      "INFO 09-13 07:26:23 [backends.py:136] Cache the graph of shape None for later use\n",
      "INFO 09-13 07:26:52 [backends.py:148] Compiling a graph for general shape takes 30.98 s\n",
      "INFO 09-13 07:27:07 [monitor.py:33] torch.compile takes 39.44 s in total\n",
      "INFO 09-13 07:27:08 [kv_cache_utils.py:634] GPU KV cache size: 332,352 tokens\n",
      "INFO 09-13 07:27:08 [kv_cache_utils.py:637] Maximum concurrency for 32,768 tokens per request: 10.14x\n",
      "INFO 09-13 07:27:38 [gpu_model_runner.py:1686] Graph capturing finished in 29 secs, took 0.53 GiB\n",
      "INFO 09-13 07:27:38 [core.py:159] init engine (profile, create kv cache, warmup model) took 85.80 seconds\n",
      "INFO 09-13 07:27:38 [core_client.py:439] Core engine process 0 ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-09-13 07:27:52] INFO task.py:420: Building contexts for gsm8k on rank 0...\n",
      "100%|██████████| 1319/1319 [00:03<00:00, 346.91it/s]\n",
      "[2025-09-13 07:27:56] INFO evaluator.py:517: Running generate_until requests\n",
      "Running generate_until requests:   0%|          | 0/1319 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949f3561f01b4843afcd859900fbc1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1319 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running generate_until requests: 100%|██████████| 1319/1319 [03:18<00:00,  6.64it/s] \n",
      "[rank0]:[W913 07:31:19.830507743 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "import lm_eval\n",
    "from lm_eval.utils import make_table\n",
    "\n",
    "results_w4a16 = lm_eval.simple_evaluate(\n",
    "    model=\"vllm\" if use_gpu else \"hf\",\n",
    "    model_args={\n",
    "        \"pretrained\": model_dir,\n",
    "        \"add_bos_token\": True,\n",
    "        \"device\": \"auto\"\n",
    "    },\n",
    "    tasks=[\"gsm8k\"],\n",
    "    batch_size=\"auto\" if use_gpu else 4,\n",
    "    limit=None if use_gpu else 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Tasks|Version|     Filter     |n-shot|  Metric   |   |Value |   |Stderr|\n",
      "|-----|------:|----------------|-----:|-----------|---|-----:|---|-----:|\n",
      "|gsm8k|      3|flexible-extract|     5|exact_match|↑  |0.8279|±  |0.0104|\n",
      "|     |       |strict-match    |     5|exact_match|↑  |0.8059|±  |0.0109|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_table(results_w4a16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3\\) Calibrated Compression with a Dataset\n",
    "\n",
    "Some more advanced compression algorithms require a small dataset of calibration samples that are meant to be a representative random subset of the language the model will see at inference.\n",
    "\n",
    "We will show how the previous section can be augmented with a calibration dataset and GPTQ, one of the first published LLM compression algorithms.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> This will take several minutes if no GPU is available\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use a new recipe running GPTQ (https://arxiv.org/abs/2210.17323)\n",
    "# to reduce error caused by quantization. GPTQ requires a calibration dataset.\n",
    "from llmcompressor.modifiers.quantization import GPTQModifier\n",
    "\n",
    "recipe = GPTQModifier(targets=\"Linear\", scheme=\"W4A16\", ignore=[\"lm_head\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3594b028bfa8471cbc5752bb377edc79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Create the calibration dataset, using Huggingface datasets API\n",
    "dataset_id = \"HuggingFaceH4/ultrachat_200k\"\n",
    "\n",
    "# Select number of samples. 512 samples is a good place to start.\n",
    "# Increasing the number of samples can improve accuracy.\n",
    "num_calibration_samples = 512 if use_gpu else 4\n",
    "max_sequence_length = 2048 if use_gpu else 16\n",
    "\n",
    "# Load dataset\n",
    "ds = load_dataset(dataset_id, split=\"train_sft\")\n",
    "# Shuffle and grab only the number of samples we need\n",
    "ds = ds.shuffle(seed=42).select(range(num_calibration_samples))\n",
    "\n",
    "# Preprocess and tokenize into format the model uses\n",
    "def preprocess(example):\n",
    "    text = tokenizer.apply_chat_template(\n",
    "            example[\"messages\"],\n",
    "            tokenize=False,\n",
    "        )\n",
    "    return tokenizer(\n",
    "        text,\n",
    "        padding=False,\n",
    "        max_length=max_sequence_length,\n",
    "        truncation=True,\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "\n",
    "ds = ds.map(preprocess, remove_columns=ds.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-09-13 07:31:35] INFO modeling.py:990: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d215e57e207443aa5d159912caa6180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:33:05.911454+0000 | reset | INFO - Compression lifecycle reset\n",
      "2025-09-13T07:33:05.912581+0000 | from_modifiers | INFO - Creating recipe from modifiers\n",
      "2025-09-13T07:33:05.914388+0000 | _check_build_quant_modifier | WARNING - GPTQ quantization is set to True without an active quantization modifier.\n",
      "2025-09-13T07:33:05.915037+0000 | _build_quant_modifier | INFO - Building quantization modifier with args: {'targets': 'Linear', 'scheme': 'W4A16', 'ignore': ['lm_head']}\n",
      "2025-09-13T07:33:05.948516+0000 | _check_calibration_data | INFO - Skipping QuantizationModifier calibration, it is not required for the provided quantization config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing intermediates cache: 100%|██████████| 512/512 [00:00<00:00, 777.49it/s]\n",
      "(1/29): Calibrating: 100%|██████████| 512/512 [00:19<00:00, 25.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:33:29.042890+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:33:30.599837+0000 | compress | METRIC - time 1.56s\n",
      "2025-09-13T07:33:30.600729+0000 | compress | METRIC - error 1758.89\n",
      "2025-09-13T07:33:30.601588+0000 | compress | METRIC - GPU 0 | usage: 77.73% | total memory: 48 GB\n",
      "2025-09-13T07:33:30.601931+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:33:30.602581+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:33:32.035045+0000 | compress | METRIC - time 1.43s\n",
      "2025-09-13T07:33:32.035692+0000 | compress | METRIC - error 394.13\n",
      "2025-09-13T07:33:32.036394+0000 | compress | METRIC - GPU 0 | usage: 77.73% | total memory: 48 GB\n",
      "2025-09-13T07:33:32.036869+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:33:32.037452+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:33:33.473278+0000 | compress | METRIC - time 1.44s\n",
      "2025-09-13T07:33:33.474256+0000 | compress | METRIC - error 42.71\n",
      "2025-09-13T07:33:33.474873+0000 | compress | METRIC - GPU 0 | usage: 77.73% | total memory: 48 GB\n",
      "2025-09-13T07:33:33.475227+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:33:33.475916+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:33:34.919975+0000 | compress | METRIC - time 1.44s\n",
      "2025-09-13T07:33:34.920914+0000 | compress | METRIC - error 210.91\n",
      "2025-09-13T07:33:34.921616+0000 | compress | METRIC - GPU 0 | usage: 77.73% | total memory: 48 GB\n",
      "2025-09-13T07:33:34.921938+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:33:34.922606+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:33:36.516928+0000 | compress | METRIC - time 1.59s\n",
      "2025-09-13T07:33:36.517813+0000 | compress | METRIC - error 42249.09\n",
      "2025-09-13T07:33:36.518559+0000 | compress | METRIC - GPU 0 | usage: 77.73% | total memory: 48 GB\n",
      "2025-09-13T07:33:36.518904+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:33:36.519573+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:33:38.127792+0000 | compress | METRIC - time 1.61s\n",
      "2025-09-13T07:33:38.128696+0000 | compress | METRIC - error 1459.98\n",
      "2025-09-13T07:33:38.129279+0000 | compress | METRIC - GPU 0 | usage: 77.73% | total memory: 48 GB\n",
      "2025-09-13T07:33:38.129756+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:33:38.130556+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.0.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:33:46.593937+0000 | compress | METRIC - time 8.46s\n",
      "2025-09-13T07:33:46.596699+0000 | compress | METRIC - error 339.70\n",
      "2025-09-13T07:33:46.597263+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:33:46.597667+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(1/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 163.41it/s]\n",
      "(2/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:34:09.976152+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:34:11.482307+0000 | compress | METRIC - time 1.51s\n",
      "2025-09-13T07:34:11.483362+0000 | compress | METRIC - error 760.12\n",
      "2025-09-13T07:34:11.484015+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:34:11.484399+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:34:11.485051+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:34:12.902744+0000 | compress | METRIC - time 1.42s\n",
      "2025-09-13T07:34:12.903758+0000 | compress | METRIC - error 196.17\n",
      "2025-09-13T07:34:12.904505+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:34:12.904862+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:34:12.905558+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:34:14.339826+0000 | compress | METRIC - time 1.43s\n",
      "2025-09-13T07:34:14.340830+0000 | compress | METRIC - error 59.33\n",
      "2025-09-13T07:34:14.341552+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:34:14.341895+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:34:14.342590+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:34:15.804089+0000 | compress | METRIC - time 1.46s\n",
      "2025-09-13T07:34:15.805032+0000 | compress | METRIC - error 48.94\n",
      "2025-09-13T07:34:15.805753+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:34:15.806126+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:34:15.806792+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:34:17.409478+0000 | compress | METRIC - time 1.60s\n",
      "2025-09-13T07:34:17.410511+0000 | compress | METRIC - error 80401.25\n",
      "2025-09-13T07:34:17.411124+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:34:17.411524+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:34:17.412196+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:34:19.016244+0000 | compress | METRIC - time 1.60s\n",
      "2025-09-13T07:34:19.017227+0000 | compress | METRIC - error 33200.04\n",
      "2025-09-13T07:34:19.017890+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:34:19.018235+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:34:19.018918+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.1.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:34:27.522962+0000 | compress | METRIC - time 8.50s\n",
      "2025-09-13T07:34:27.525509+0000 | compress | METRIC - error 407.44\n",
      "2025-09-13T07:34:27.526372+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:34:27.526805+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(2/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 181.05it/s]\n",
      "(3/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:34:50.601019+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:34:52.123176+0000 | compress | METRIC - time 1.52s\n",
      "2025-09-13T07:34:52.124193+0000 | compress | METRIC - error 3996.47\n",
      "2025-09-13T07:34:52.125090+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:34:52.125584+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:34:52.126530+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:34:53.564187+0000 | compress | METRIC - time 1.44s\n",
      "2025-09-13T07:34:53.565230+0000 | compress | METRIC - error 1063.97\n",
      "2025-09-13T07:34:53.566130+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:34:53.566618+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:34:53.567550+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:34:55.002011+0000 | compress | METRIC - time 1.43s\n",
      "2025-09-13T07:34:55.003086+0000 | compress | METRIC - error 191.87\n",
      "2025-09-13T07:34:55.003981+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:34:55.004458+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:34:55.005378+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:34:56.466170+0000 | compress | METRIC - time 1.46s\n",
      "2025-09-13T07:34:56.467200+0000 | compress | METRIC - error 106.61\n",
      "2025-09-13T07:34:56.468048+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:34:56.468528+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:34:56.469412+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:34:58.148089+0000 | compress | METRIC - time 1.68s\n",
      "2025-09-13T07:34:58.149092+0000 | compress | METRIC - error 88534.26\n",
      "2025-09-13T07:34:58.149701+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:34:58.150041+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:34:58.150926+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:34:59.815482+0000 | compress | METRIC - time 1.66s\n",
      "2025-09-13T07:34:59.816645+0000 | compress | METRIC - error 41493.83\n",
      "2025-09-13T07:34:59.817269+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:34:59.817754+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:34:59.818405+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.2.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:35:08.283522+0000 | compress | METRIC - time 8.46s\n",
      "2025-09-13T07:35:08.286675+0000 | compress | METRIC - error 757.75\n",
      "2025-09-13T07:35:08.287392+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:35:08.287884+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(3/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 185.14it/s]\n",
      "(4/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:35:31.116729+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:35:32.631376+0000 | compress | METRIC - time 1.51s\n",
      "2025-09-13T07:35:32.632379+0000 | compress | METRIC - error 4646.26\n",
      "2025-09-13T07:35:32.632903+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:35:32.633347+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:35:32.634406+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:35:34.068636+0000 | compress | METRIC - time 1.43s\n",
      "2025-09-13T07:35:34.069626+0000 | compress | METRIC - error 1153.94\n",
      "2025-09-13T07:35:34.070251+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:35:34.070643+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:35:34.071274+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:35:35.524423+0000 | compress | METRIC - time 1.45s\n",
      "2025-09-13T07:35:35.525477+0000 | compress | METRIC - error 319.80\n",
      "2025-09-13T07:35:35.526113+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:35:35.526637+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:35:35.527221+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:35:36.987065+0000 | compress | METRIC - time 1.46s\n",
      "2025-09-13T07:35:36.988241+0000 | compress | METRIC - error 246.92\n",
      "2025-09-13T07:35:36.989203+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:35:36.989674+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:35:36.990610+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:35:38.612806+0000 | compress | METRIC - time 1.62s\n",
      "2025-09-13T07:35:38.613821+0000 | compress | METRIC - error 138243.62\n",
      "2025-09-13T07:35:38.614406+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:35:38.614748+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:35:38.615803+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:35:40.240714+0000 | compress | METRIC - time 1.62s\n",
      "2025-09-13T07:35:40.241392+0000 | compress | METRIC - error 106198.49\n",
      "2025-09-13T07:35:40.241997+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:35:40.242620+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:35:40.243314+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.3.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:35:48.680221+0000 | compress | METRIC - time 8.44s\n",
      "2025-09-13T07:35:48.683456+0000 | compress | METRIC - error 16177.14\n",
      "2025-09-13T07:35:48.684218+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:35:48.684719+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(4/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 183.20it/s]\n",
      "(5/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:36:11.632812+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:36:13.125153+0000 | compress | METRIC - time 1.49s\n",
      "2025-09-13T07:36:13.125830+0000 | compress | METRIC - error 11601.06\n",
      "2025-09-13T07:36:13.126463+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:36:13.126843+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:36:13.127539+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:36:14.551394+0000 | compress | METRIC - time 1.42s\n",
      "2025-09-13T07:36:14.552398+0000 | compress | METRIC - error 2534.04\n",
      "2025-09-13T07:36:14.552911+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:36:14.553231+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:36:14.554007+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:36:16.000370+0000 | compress | METRIC - time 1.45s\n",
      "2025-09-13T07:36:16.001323+0000 | compress | METRIC - error 967.90\n",
      "2025-09-13T07:36:16.001999+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:36:16.002341+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:36:16.002967+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:36:17.441107+0000 | compress | METRIC - time 1.44s\n",
      "2025-09-13T07:36:17.441876+0000 | compress | METRIC - error 237.02\n",
      "2025-09-13T07:36:17.442489+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:36:17.442843+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:36:17.443551+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:36:19.082545+0000 | compress | METRIC - time 1.64s\n",
      "2025-09-13T07:36:19.083734+0000 | compress | METRIC - error 148418.02\n",
      "2025-09-13T07:36:19.084403+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:36:19.084770+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:36:19.085461+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:36:20.713586+0000 | compress | METRIC - time 1.63s\n",
      "2025-09-13T07:36:20.714701+0000 | compress | METRIC - error 102933.59\n",
      "2025-09-13T07:36:20.715366+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:36:20.715728+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:36:20.716570+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.4.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:36:29.166089+0000 | compress | METRIC - time 8.45s\n",
      "2025-09-13T07:36:29.168725+0000 | compress | METRIC - error 2280.93\n",
      "2025-09-13T07:36:29.169559+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:36:29.170002+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(5/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 183.78it/s]\n",
      "(6/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:36:52.430094+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:36:53.926526+0000 | compress | METRIC - time 1.50s\n",
      "2025-09-13T07:36:53.927652+0000 | compress | METRIC - error 10932.83\n",
      "2025-09-13T07:36:53.928249+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:36:53.928608+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:36:53.929252+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:36:55.362874+0000 | compress | METRIC - time 1.43s\n",
      "2025-09-13T07:36:55.363947+0000 | compress | METRIC - error 2225.24\n",
      "2025-09-13T07:36:55.364547+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:36:55.365066+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:36:55.365667+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:36:56.770701+0000 | compress | METRIC - time 1.40s\n",
      "2025-09-13T07:36:56.771720+0000 | compress | METRIC - error 987.02\n",
      "2025-09-13T07:36:56.772426+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:36:56.772783+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:36:56.773489+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:36:58.253697+0000 | compress | METRIC - time 1.48s\n",
      "2025-09-13T07:36:58.254642+0000 | compress | METRIC - error 262.87\n",
      "2025-09-13T07:36:58.255211+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:36:58.255581+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:36:58.256522+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:36:59.913573+0000 | compress | METRIC - time 1.66s\n",
      "2025-09-13T07:36:59.914685+0000 | compress | METRIC - error 196694.88\n",
      "2025-09-13T07:36:59.915473+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:36:59.915879+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:36:59.916725+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:37:01.513427+0000 | compress | METRIC - time 1.60s\n",
      "2025-09-13T07:37:01.514083+0000 | compress | METRIC - error 160455.03\n",
      "2025-09-13T07:37:01.514859+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:37:01.515238+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:37:01.516066+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.5.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:37:09.900508+0000 | compress | METRIC - time 8.38s\n",
      "2025-09-13T07:37:09.902951+0000 | compress | METRIC - error 1119.48\n",
      "2025-09-13T07:37:09.903703+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:37:09.904094+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(6/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 183.42it/s]\n",
      "(7/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:37:32.833428+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:37:34.333211+0000 | compress | METRIC - time 1.50s\n",
      "2025-09-13T07:37:34.334167+0000 | compress | METRIC - error 7173.37\n",
      "2025-09-13T07:37:34.334795+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:37:34.335178+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:37:34.335863+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:37:35.786677+0000 | compress | METRIC - time 1.45s\n",
      "2025-09-13T07:37:35.787612+0000 | compress | METRIC - error 1422.52\n",
      "2025-09-13T07:37:35.788209+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:37:35.788611+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:37:35.789308+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:37:37.268772+0000 | compress | METRIC - time 1.48s\n",
      "2025-09-13T07:37:37.269885+0000 | compress | METRIC - error 712.34\n",
      "2025-09-13T07:37:37.270425+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:37:37.270755+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:37:37.271659+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:37:38.692598+0000 | compress | METRIC - time 1.42s\n",
      "2025-09-13T07:37:38.693489+0000 | compress | METRIC - error 344.87\n",
      "2025-09-13T07:37:38.694222+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:37:38.694632+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:37:38.695386+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:37:40.260571+0000 | compress | METRIC - time 1.56s\n",
      "2025-09-13T07:37:40.261656+0000 | compress | METRIC - error 58798.20\n",
      "2025-09-13T07:37:40.262553+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:37:40.263014+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:37:40.263924+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:37:41.857656+0000 | compress | METRIC - time 1.59s\n",
      "2025-09-13T07:37:41.858711+0000 | compress | METRIC - error 38729.52\n",
      "2025-09-13T07:37:41.859440+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:37:41.859793+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:37:41.860468+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.6.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:37:50.161131+0000 | compress | METRIC - time 8.30s\n",
      "2025-09-13T07:37:50.163669+0000 | compress | METRIC - error 2341.11\n",
      "2025-09-13T07:37:50.164244+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:37:50.164638+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(7/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 185.18it/s]\n",
      "(8/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:38:12.935963+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:38:14.408414+0000 | compress | METRIC - time 1.47s\n",
      "2025-09-13T07:38:14.409438+0000 | compress | METRIC - error 8648.19\n",
      "2025-09-13T07:38:14.410129+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:38:14.410527+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:38:14.411273+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:38:15.799877+0000 | compress | METRIC - time 1.39s\n",
      "2025-09-13T07:38:15.800937+0000 | compress | METRIC - error 1481.31\n",
      "2025-09-13T07:38:15.801652+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:38:15.802031+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:38:15.802751+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:38:17.228488+0000 | compress | METRIC - time 1.43s\n",
      "2025-09-13T07:38:17.229561+0000 | compress | METRIC - error 1470.67\n",
      "2025-09-13T07:38:17.230240+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:38:17.230702+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:38:17.231527+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:38:18.647136+0000 | compress | METRIC - time 1.42s\n",
      "2025-09-13T07:38:18.648091+0000 | compress | METRIC - error 762.86\n",
      "2025-09-13T07:38:18.648815+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:38:18.649184+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:38:18.649906+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:38:20.251681+0000 | compress | METRIC - time 1.60s\n",
      "2025-09-13T07:38:20.252739+0000 | compress | METRIC - error 40878.95\n",
      "2025-09-13T07:38:20.253630+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:38:20.254078+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:38:20.254993+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:38:21.850563+0000 | compress | METRIC - time 1.60s\n",
      "2025-09-13T07:38:21.851726+0000 | compress | METRIC - error 35836.20\n",
      "2025-09-13T07:38:21.852491+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:38:21.853110+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:38:21.853849+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.7.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:38:30.116227+0000 | compress | METRIC - time 8.26s\n",
      "2025-09-13T07:38:30.119264+0000 | compress | METRIC - error 3674.32\n",
      "2025-09-13T07:38:30.120108+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:38:30.120564+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(8/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 185.94it/s]\n",
      "(9/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:38:52.921523+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:38:54.422133+0000 | compress | METRIC - time 1.50s\n",
      "2025-09-13T07:38:54.423113+0000 | compress | METRIC - error 12965.93\n",
      "2025-09-13T07:38:54.423792+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:38:54.424134+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:38:54.424880+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:38:55.865019+0000 | compress | METRIC - time 1.44s\n",
      "2025-09-13T07:38:55.866060+0000 | compress | METRIC - error 2899.59\n",
      "2025-09-13T07:38:55.866736+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:38:55.867160+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:38:55.867864+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:38:57.343952+0000 | compress | METRIC - time 1.48s\n",
      "2025-09-13T07:38:57.345030+0000 | compress | METRIC - error 1221.41\n",
      "2025-09-13T07:38:57.345718+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:38:57.346215+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:38:57.346817+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:38:58.804062+0000 | compress | METRIC - time 1.46s\n",
      "2025-09-13T07:38:58.805002+0000 | compress | METRIC - error 718.69\n",
      "2025-09-13T07:38:58.805558+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:38:58.805870+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:38:58.806693+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:39:00.470191+0000 | compress | METRIC - time 1.66s\n",
      "2025-09-13T07:39:00.471216+0000 | compress | METRIC - error 43484.26\n",
      "2025-09-13T07:39:00.471929+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:39:00.472297+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:39:00.473091+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:39:02.116211+0000 | compress | METRIC - time 1.64s\n",
      "2025-09-13T07:39:02.117278+0000 | compress | METRIC - error 40892.88\n",
      "2025-09-13T07:39:02.118190+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:39:02.118690+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:39:02.119579+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.8.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:39:10.484379+0000 | compress | METRIC - time 8.36s\n",
      "2025-09-13T07:39:10.487294+0000 | compress | METRIC - error 3909.47\n",
      "2025-09-13T07:39:10.488064+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:39:10.488458+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(9/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 185.46it/s]\n",
      "(10/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:39:33.292836+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:39:34.861383+0000 | compress | METRIC - time 1.57s\n",
      "2025-09-13T07:39:34.862495+0000 | compress | METRIC - error 11290.35\n",
      "2025-09-13T07:39:34.863109+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:39:34.863643+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:39:34.864322+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:39:36.317787+0000 | compress | METRIC - time 1.45s\n",
      "2025-09-13T07:39:36.318831+0000 | compress | METRIC - error 1992.41\n",
      "2025-09-13T07:39:36.319520+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:39:36.319915+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:39:36.320657+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:39:37.767665+0000 | compress | METRIC - time 1.45s\n",
      "2025-09-13T07:39:37.768695+0000 | compress | METRIC - error 1896.59\n",
      "2025-09-13T07:39:37.769346+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:39:37.769691+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:39:37.770417+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:39:39.215975+0000 | compress | METRIC - time 1.45s\n",
      "2025-09-13T07:39:39.217025+0000 | compress | METRIC - error 1462.26\n",
      "2025-09-13T07:39:39.217805+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:39:39.218139+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:39:39.218823+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:39:40.817012+0000 | compress | METRIC - time 1.60s\n",
      "2025-09-13T07:39:40.818077+0000 | compress | METRIC - error 113681.70\n",
      "2025-09-13T07:39:40.818831+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:39:40.819180+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:39:40.819871+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:39:42.377971+0000 | compress | METRIC - time 1.56s\n",
      "2025-09-13T07:39:42.378998+0000 | compress | METRIC - error 71281.42\n",
      "2025-09-13T07:39:42.379691+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:39:42.380157+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:39:42.380726+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.9.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:39:50.944200+0000 | compress | METRIC - time 8.56s\n",
      "2025-09-13T07:39:50.946791+0000 | compress | METRIC - error 3713.74\n",
      "2025-09-13T07:39:50.947518+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:39:50.947879+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(10/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 185.20it/s]\n",
      "(11/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:40:13.965006+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:40:15.426145+0000 | compress | METRIC - time 1.46s\n",
      "2025-09-13T07:40:15.427105+0000 | compress | METRIC - error 9752.68\n",
      "2025-09-13T07:40:15.427874+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:40:15.428201+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:40:15.428836+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:40:16.825583+0000 | compress | METRIC - time 1.40s\n",
      "2025-09-13T07:40:16.826666+0000 | compress | METRIC - error 1867.76\n",
      "2025-09-13T07:40:16.827473+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:40:16.828021+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:40:16.828684+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:40:18.212101+0000 | compress | METRIC - time 1.38s\n",
      "2025-09-13T07:40:18.213043+0000 | compress | METRIC - error 1095.62\n",
      "2025-09-13T07:40:18.213788+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:40:18.214187+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:40:18.214996+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:40:19.633426+0000 | compress | METRIC - time 1.42s\n",
      "2025-09-13T07:40:19.634536+0000 | compress | METRIC - error 862.08\n",
      "2025-09-13T07:40:19.635085+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:40:19.635799+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:40:19.636592+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:40:21.197896+0000 | compress | METRIC - time 1.56s\n",
      "2025-09-13T07:40:21.198967+0000 | compress | METRIC - error 44829.61\n",
      "2025-09-13T07:40:21.199612+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:40:21.199937+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:40:21.200603+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:40:22.771977+0000 | compress | METRIC - time 1.57s\n",
      "2025-09-13T07:40:22.772991+0000 | compress | METRIC - error 39728.82\n",
      "2025-09-13T07:40:22.773764+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:40:22.774150+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:40:22.774965+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.10.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:40:31.146269+0000 | compress | METRIC - time 8.37s\n",
      "2025-09-13T07:40:31.148793+0000 | compress | METRIC - error 3282.58\n",
      "2025-09-13T07:40:31.149481+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:40:31.149877+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(11/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 182.78it/s]\n",
      "(12/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 24.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:40:54.518717+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:40:56.035228+0000 | compress | METRIC - time 1.52s\n",
      "2025-09-13T07:40:56.036437+0000 | compress | METRIC - error 11233.37\n",
      "2025-09-13T07:40:56.037117+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:40:56.037573+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:40:56.038262+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:40:57.470100+0000 | compress | METRIC - time 1.43s\n",
      "2025-09-13T07:40:57.471158+0000 | compress | METRIC - error 2421.30\n",
      "2025-09-13T07:40:57.471862+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:40:57.472347+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:40:57.472910+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:40:58.900218+0000 | compress | METRIC - time 1.43s\n",
      "2025-09-13T07:40:58.901301+0000 | compress | METRIC - error 993.88\n",
      "2025-09-13T07:40:58.901976+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:40:58.902315+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:40:58.903035+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:41:00.383654+0000 | compress | METRIC - time 1.48s\n",
      "2025-09-13T07:41:00.384690+0000 | compress | METRIC - error 864.58\n",
      "2025-09-13T07:41:00.385303+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:41:00.385705+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:41:00.386379+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:41:02.002456+0000 | compress | METRIC - time 1.62s\n",
      "2025-09-13T07:41:02.003545+0000 | compress | METRIC - error 39146.48\n",
      "2025-09-13T07:41:02.004194+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:41:02.004671+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:41:02.005227+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:41:03.650606+0000 | compress | METRIC - time 1.65s\n",
      "2025-09-13T07:41:03.651590+0000 | compress | METRIC - error 37490.79\n",
      "2025-09-13T07:41:03.652239+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:41:03.652691+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:41:03.653385+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.11.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:41:12.168096+0000 | compress | METRIC - time 8.51s\n",
      "2025-09-13T07:41:12.171661+0000 | compress | METRIC - error 3063.11\n",
      "2025-09-13T07:41:12.172523+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:41:12.172871+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(12/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 182.29it/s]\n",
      "(13/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 24.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:41:35.561543+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:41:37.060499+0000 | compress | METRIC - time 1.50s\n",
      "2025-09-13T07:41:37.061507+0000 | compress | METRIC - error 11869.59\n",
      "2025-09-13T07:41:37.062246+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:41:37.062819+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:41:37.063526+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:41:38.508928+0000 | compress | METRIC - time 1.45s\n",
      "2025-09-13T07:41:38.509874+0000 | compress | METRIC - error 2524.18\n",
      "2025-09-13T07:41:38.510620+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:41:38.511005+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:41:38.511857+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:41:39.970132+0000 | compress | METRIC - time 1.46s\n",
      "2025-09-13T07:41:39.971202+0000 | compress | METRIC - error 1258.03\n",
      "2025-09-13T07:41:39.972002+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:41:39.972425+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:41:39.973237+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:41:41.450756+0000 | compress | METRIC - time 1.48s\n",
      "2025-09-13T07:41:41.451494+0000 | compress | METRIC - error 894.31\n",
      "2025-09-13T07:41:41.452156+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:41:41.452540+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:41:41.453193+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:41:43.071165+0000 | compress | METRIC - time 1.62s\n",
      "2025-09-13T07:41:43.072218+0000 | compress | METRIC - error 37129.05\n",
      "2025-09-13T07:41:43.072746+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:41:43.073128+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:41:43.074259+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:41:44.687051+0000 | compress | METRIC - time 1.61s\n",
      "2025-09-13T07:41:44.688089+0000 | compress | METRIC - error 37506.70\n",
      "2025-09-13T07:41:44.688730+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:41:44.689059+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:41:44.689708+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.12.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:41:53.195467+0000 | compress | METRIC - time 8.51s\n",
      "2025-09-13T07:41:53.196254+0000 | compress | METRIC - error 3085.29\n",
      "2025-09-13T07:41:53.196992+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:41:53.197411+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(13/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 184.13it/s]\n",
      "(14/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 24.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:42:16.512225+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:42:18.014267+0000 | compress | METRIC - time 1.50s\n",
      "2025-09-13T07:42:18.015301+0000 | compress | METRIC - error 12226.42\n",
      "2025-09-13T07:42:18.015975+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:42:18.016409+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:42:18.017228+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:42:19.450676+0000 | compress | METRIC - time 1.43s\n",
      "2025-09-13T07:42:19.451791+0000 | compress | METRIC - error 2274.22\n",
      "2025-09-13T07:42:19.452462+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:42:19.452933+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:42:19.453903+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:42:20.884351+0000 | compress | METRIC - time 1.43s\n",
      "2025-09-13T07:42:20.885478+0000 | compress | METRIC - error 1551.03\n",
      "2025-09-13T07:42:20.886310+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:42:20.886789+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:42:20.887701+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:42:22.341411+0000 | compress | METRIC - time 1.45s\n",
      "2025-09-13T07:42:22.342463+0000 | compress | METRIC - error 1312.93\n",
      "2025-09-13T07:42:22.343251+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:42:22.343737+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:42:22.344638+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:42:23.913936+0000 | compress | METRIC - time 1.57s\n",
      "2025-09-13T07:42:23.914930+0000 | compress | METRIC - error 39149.38\n",
      "2025-09-13T07:42:23.915733+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:42:23.916091+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:42:23.916801+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:42:25.509998+0000 | compress | METRIC - time 1.59s\n",
      "2025-09-13T07:42:25.510957+0000 | compress | METRIC - error 36865.31\n",
      "2025-09-13T07:42:25.511735+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:42:25.512093+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:42:25.512801+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.13.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:42:33.836161+0000 | compress | METRIC - time 8.32s\n",
      "2025-09-13T07:42:33.838618+0000 | compress | METRIC - error 2974.21\n",
      "2025-09-13T07:42:33.839249+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:42:33.839651+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(14/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 184.16it/s]\n",
      "(15/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:42:56.869435+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:42:58.343155+0000 | compress | METRIC - time 1.47s\n",
      "2025-09-13T07:42:58.344219+0000 | compress | METRIC - error 17300.34\n",
      "2025-09-13T07:42:58.344857+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:42:58.345209+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:42:58.345860+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:42:59.789548+0000 | compress | METRIC - time 1.44s\n",
      "2025-09-13T07:42:59.790623+0000 | compress | METRIC - error 3375.02\n",
      "2025-09-13T07:42:59.791234+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:42:59.791598+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:42:59.792285+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:43:01.225540+0000 | compress | METRIC - time 1.43s\n",
      "2025-09-13T07:43:01.226693+0000 | compress | METRIC - error 1673.80\n",
      "2025-09-13T07:43:01.227452+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:43:01.227885+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:43:01.228590+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:43:02.652001+0000 | compress | METRIC - time 1.42s\n",
      "2025-09-13T07:43:02.652981+0000 | compress | METRIC - error 1079.24\n",
      "2025-09-13T07:43:02.653700+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:43:02.654059+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:43:02.654693+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:43:04.300447+0000 | compress | METRIC - time 1.65s\n",
      "2025-09-13T07:43:04.301514+0000 | compress | METRIC - error 40662.73\n",
      "2025-09-13T07:43:04.302160+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:43:04.302593+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:43:04.303367+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:43:05.868624+0000 | compress | METRIC - time 1.56s\n",
      "2025-09-13T07:43:05.869580+0000 | compress | METRIC - error 40720.02\n",
      "2025-09-13T07:43:05.870230+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:43:05.870694+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:43:05.871491+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.14.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:43:14.561510+0000 | compress | METRIC - time 8.69s\n",
      "2025-09-13T07:43:14.563965+0000 | compress | METRIC - error 3315.95\n",
      "2025-09-13T07:43:14.564634+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:43:14.565064+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(15/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 184.13it/s]\n",
      "(16/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:43:37.435985+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:43:38.916368+0000 | compress | METRIC - time 1.48s\n",
      "2025-09-13T07:43:38.917399+0000 | compress | METRIC - error 12707.10\n",
      "2025-09-13T07:43:38.918198+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:43:38.918675+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:43:38.919610+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:43:40.360209+0000 | compress | METRIC - time 1.44s\n",
      "2025-09-13T07:43:40.361227+0000 | compress | METRIC - error 2774.93\n",
      "2025-09-13T07:43:40.362062+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:43:40.362519+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:43:40.363475+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:43:41.817873+0000 | compress | METRIC - time 1.45s\n",
      "2025-09-13T07:43:41.818918+0000 | compress | METRIC - error 1200.35\n",
      "2025-09-13T07:43:41.819790+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:43:41.820232+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:43:41.821119+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:43:43.289899+0000 | compress | METRIC - time 1.47s\n",
      "2025-09-13T07:43:43.290872+0000 | compress | METRIC - error 906.82\n",
      "2025-09-13T07:43:43.291869+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:43:43.292299+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:43:43.293156+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:43:44.908785+0000 | compress | METRIC - time 1.62s\n",
      "2025-09-13T07:43:44.909847+0000 | compress | METRIC - error 35896.82\n",
      "2025-09-13T07:43:44.910609+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:43:44.911037+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:43:44.911978+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:43:46.515907+0000 | compress | METRIC - time 1.60s\n",
      "2025-09-13T07:43:46.516855+0000 | compress | METRIC - error 37170.42\n",
      "2025-09-13T07:43:46.517623+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:43:46.518083+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:43:46.518976+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.15.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:43:55.030467+0000 | compress | METRIC - time 8.51s\n",
      "2025-09-13T07:43:55.032961+0000 | compress | METRIC - error 3128.59\n",
      "2025-09-13T07:43:55.033577+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:43:55.033927+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(16/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 184.61it/s]\n",
      "(17/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:44:18.069192+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:44:19.606971+0000 | compress | METRIC - time 1.54s\n",
      "2025-09-13T07:44:19.607978+0000 | compress | METRIC - error 13904.45\n",
      "2025-09-13T07:44:19.608672+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:44:19.609017+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:44:19.609735+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:44:21.037566+0000 | compress | METRIC - time 1.43s\n",
      "2025-09-13T07:44:21.038635+0000 | compress | METRIC - error 2701.95\n",
      "2025-09-13T07:44:21.039263+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:44:21.039625+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:44:21.040324+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:44:22.459677+0000 | compress | METRIC - time 1.42s\n",
      "2025-09-13T07:44:22.460679+0000 | compress | METRIC - error 1871.94\n",
      "2025-09-13T07:44:22.461360+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:44:22.461722+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:44:22.462442+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:44:23.923993+0000 | compress | METRIC - time 1.46s\n",
      "2025-09-13T07:44:23.925038+0000 | compress | METRIC - error 1281.58\n",
      "2025-09-13T07:44:23.925833+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:44:23.926195+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:44:23.926878+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:44:25.503894+0000 | compress | METRIC - time 1.58s\n",
      "2025-09-13T07:44:25.504952+0000 | compress | METRIC - error 36451.47\n",
      "2025-09-13T07:44:25.505584+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:44:25.505912+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:44:25.506576+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:44:27.134931+0000 | compress | METRIC - time 1.63s\n",
      "2025-09-13T07:44:27.136021+0000 | compress | METRIC - error 37642.85\n",
      "2025-09-13T07:44:27.136667+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:44:27.137074+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:44:27.137719+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.16.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:44:35.792869+0000 | compress | METRIC - time 8.65s\n",
      "2025-09-13T07:44:35.795400+0000 | compress | METRIC - error 3207.98\n",
      "2025-09-13T07:44:35.796144+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:44:35.796549+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(17/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 183.20it/s]\n",
      "(18/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 24.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:44:59.137060+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:45:00.654415+0000 | compress | METRIC - time 1.52s\n",
      "2025-09-13T07:45:00.655429+0000 | compress | METRIC - error 15815.09\n",
      "2025-09-13T07:45:00.656158+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:45:00.656549+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:45:00.657221+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:45:02.119753+0000 | compress | METRIC - time 1.46s\n",
      "2025-09-13T07:45:02.120821+0000 | compress | METRIC - error 2704.02\n",
      "2025-09-13T07:45:02.121618+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:45:02.122051+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:45:02.122758+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:45:03.580749+0000 | compress | METRIC - time 1.46s\n",
      "2025-09-13T07:45:03.581872+0000 | compress | METRIC - error 2036.04\n",
      "2025-09-13T07:45:03.582622+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:45:03.583000+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:45:03.583694+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:45:05.037830+0000 | compress | METRIC - time 1.45s\n",
      "2025-09-13T07:45:05.038906+0000 | compress | METRIC - error 1200.57\n",
      "2025-09-13T07:45:05.039631+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:45:05.039984+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:45:05.040645+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:45:06.644222+0000 | compress | METRIC - time 1.60s\n",
      "2025-09-13T07:45:06.645300+0000 | compress | METRIC - error 41423.27\n",
      "2025-09-13T07:45:06.646076+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:45:06.646585+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:45:06.647176+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:45:08.246737+0000 | compress | METRIC - time 1.60s\n",
      "2025-09-13T07:45:08.247725+0000 | compress | METRIC - error 43690.76\n",
      "2025-09-13T07:45:08.248388+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:45:08.248849+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:45:08.249398+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.17.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:45:16.688590+0000 | compress | METRIC - time 8.44s\n",
      "2025-09-13T07:45:16.691322+0000 | compress | METRIC - error 4270.84\n",
      "2025-09-13T07:45:16.691944+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:45:16.692284+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(18/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 184.45it/s]\n",
      "(19/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:45:39.600541+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:45:41.117193+0000 | compress | METRIC - time 1.52s\n",
      "2025-09-13T07:45:41.117846+0000 | compress | METRIC - error 12440.67\n",
      "2025-09-13T07:45:41.118564+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:45:41.118929+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:45:41.119649+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:45:42.575902+0000 | compress | METRIC - time 1.46s\n",
      "2025-09-13T07:45:42.576917+0000 | compress | METRIC - error 2127.24\n",
      "2025-09-13T07:45:42.577701+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:45:42.578324+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:45:42.579088+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:45:44.040511+0000 | compress | METRIC - time 1.46s\n",
      "2025-09-13T07:45:44.041586+0000 | compress | METRIC - error 2291.88\n",
      "2025-09-13T07:45:44.042344+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:45:44.042724+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:45:44.043564+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:45:45.533866+0000 | compress | METRIC - time 1.49s\n",
      "2025-09-13T07:45:45.534798+0000 | compress | METRIC - error 2299.49\n",
      "2025-09-13T07:45:45.535603+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:45:45.536154+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:45:45.536814+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:45:47.204552+0000 | compress | METRIC - time 1.67s\n",
      "2025-09-13T07:45:47.205618+0000 | compress | METRIC - error 44602.63\n",
      "2025-09-13T07:45:47.206371+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:45:47.206913+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:45:47.207577+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:45:48.802227+0000 | compress | METRIC - time 1.59s\n",
      "2025-09-13T07:45:48.803389+0000 | compress | METRIC - error 47831.90\n",
      "2025-09-13T07:45:48.804177+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:45:48.804598+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:45:48.805465+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.18.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:45:57.302194+0000 | compress | METRIC - time 8.50s\n",
      "2025-09-13T07:45:57.305931+0000 | compress | METRIC - error 5529.42\n",
      "2025-09-13T07:45:57.306725+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:45:57.307109+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(19/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 183.46it/s]\n",
      "(20/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:46:20.338170+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:46:21.816723+0000 | compress | METRIC - time 1.48s\n",
      "2025-09-13T07:46:21.817784+0000 | compress | METRIC - error 16129.55\n",
      "2025-09-13T07:46:21.818676+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:46:21.819082+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:46:21.820011+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:46:23.234268+0000 | compress | METRIC - time 1.41s\n",
      "2025-09-13T07:46:23.235253+0000 | compress | METRIC - error 2512.22\n",
      "2025-09-13T07:46:23.236033+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:46:23.236501+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:46:23.237382+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:46:24.644565+0000 | compress | METRIC - time 1.41s\n",
      "2025-09-13T07:46:24.645592+0000 | compress | METRIC - error 3051.93\n",
      "2025-09-13T07:46:24.646527+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:46:24.646943+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:46:24.647838+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:46:26.114820+0000 | compress | METRIC - time 1.47s\n",
      "2025-09-13T07:46:26.115976+0000 | compress | METRIC - error 2632.09\n",
      "2025-09-13T07:46:26.116899+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:46:26.117555+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:46:26.118223+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:46:27.673779+0000 | compress | METRIC - time 1.56s\n",
      "2025-09-13T07:46:27.674759+0000 | compress | METRIC - error 52265.56\n",
      "2025-09-13T07:46:27.675688+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:46:27.676126+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:46:27.677034+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:46:29.295320+0000 | compress | METRIC - time 1.62s\n",
      "2025-09-13T07:46:29.296413+0000 | compress | METRIC - error 53206.85\n",
      "2025-09-13T07:46:29.297043+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:46:29.297403+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:46:29.298030+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.19.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:46:37.837991+0000 | compress | METRIC - time 8.54s\n",
      "2025-09-13T07:46:37.840591+0000 | compress | METRIC - error 7610.72\n",
      "2025-09-13T07:46:37.841293+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:46:37.841711+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(20/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 183.02it/s]\n",
      "(21/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 24.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:47:01.209991+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:47:02.724048+0000 | compress | METRIC - time 1.51s\n",
      "2025-09-13T07:47:02.725069+0000 | compress | METRIC - error 14406.10\n",
      "2025-09-13T07:47:02.725688+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:47:02.726151+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:47:02.726738+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:47:04.147440+0000 | compress | METRIC - time 1.42s\n",
      "2025-09-13T07:47:04.148471+0000 | compress | METRIC - error 2370.37\n",
      "2025-09-13T07:47:04.149234+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:47:04.149702+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:47:04.150589+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:47:05.572240+0000 | compress | METRIC - time 1.42s\n",
      "2025-09-13T07:47:05.573292+0000 | compress | METRIC - error 3122.10\n",
      "2025-09-13T07:47:05.573961+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:47:05.574459+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:47:05.575033+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:47:07.030678+0000 | compress | METRIC - time 1.46s\n",
      "2025-09-13T07:47:07.031740+0000 | compress | METRIC - error 2193.56\n",
      "2025-09-13T07:47:07.032384+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:47:07.032733+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:47:07.033406+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:47:08.615099+0000 | compress | METRIC - time 1.58s\n",
      "2025-09-13T07:47:08.616324+0000 | compress | METRIC - error 67451.84\n",
      "2025-09-13T07:47:08.617219+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:47:08.617595+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:47:08.618293+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:47:10.223952+0000 | compress | METRIC - time 1.61s\n",
      "2025-09-13T07:47:10.224972+0000 | compress | METRIC - error 68648.46\n",
      "2025-09-13T07:47:10.225704+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:47:10.226136+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:47:10.226698+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.20.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:47:18.730483+0000 | compress | METRIC - time 8.50s\n",
      "2025-09-13T07:47:18.732974+0000 | compress | METRIC - error 14037.74\n",
      "2025-09-13T07:47:18.733623+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:47:18.734155+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(21/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 183.66it/s]\n",
      "(22/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:47:41.680697+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:47:43.200598+0000 | compress | METRIC - time 1.52s\n",
      "2025-09-13T07:47:43.201659+0000 | compress | METRIC - error 18253.88\n",
      "2025-09-13T07:47:43.202277+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:47:43.202680+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:47:43.203495+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:47:44.655408+0000 | compress | METRIC - time 1.45s\n",
      "2025-09-13T07:47:44.656448+0000 | compress | METRIC - error 2607.52\n",
      "2025-09-13T07:47:44.656996+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:47:44.657322+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:47:44.658206+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:47:46.118789+0000 | compress | METRIC - time 1.46s\n",
      "2025-09-13T07:47:46.119465+0000 | compress | METRIC - error 4908.81\n",
      "2025-09-13T07:47:46.120195+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:47:46.120599+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:47:46.121436+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:47:47.648769+0000 | compress | METRIC - time 1.53s\n",
      "2025-09-13T07:47:47.649743+0000 | compress | METRIC - error 4268.90\n",
      "2025-09-13T07:47:47.650463+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:47:47.650839+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:47:47.651663+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:47:49.255637+0000 | compress | METRIC - time 1.60s\n",
      "2025-09-13T07:47:49.256725+0000 | compress | METRIC - error 95260.16\n",
      "2025-09-13T07:47:49.257307+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:47:49.257695+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:47:49.258371+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:47:50.890864+0000 | compress | METRIC - time 1.63s\n",
      "2025-09-13T07:47:50.891960+0000 | compress | METRIC - error 92783.08\n",
      "2025-09-13T07:47:50.892453+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:47:50.892788+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:47:50.893675+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.21.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:47:59.388266+0000 | compress | METRIC - time 8.49s\n",
      "2025-09-13T07:47:59.390773+0000 | compress | METRIC - error 22061.09\n",
      "2025-09-13T07:47:59.391488+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:47:59.391848+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(22/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 183.70it/s]\n",
      "(23/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:48:22.391629+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:48:23.934766+0000 | compress | METRIC - time 1.54s\n",
      "2025-09-13T07:48:23.935728+0000 | compress | METRIC - error 25928.19\n",
      "2025-09-13T07:48:23.936531+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:48:23.937083+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:48:23.937752+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:48:25.399822+0000 | compress | METRIC - time 1.46s\n",
      "2025-09-13T07:48:25.400815+0000 | compress | METRIC - error 3442.48\n",
      "2025-09-13T07:48:25.401412+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:48:25.401782+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:48:25.402798+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:48:26.866121+0000 | compress | METRIC - time 1.46s\n",
      "2025-09-13T07:48:26.867116+0000 | compress | METRIC - error 8129.69\n",
      "2025-09-13T07:48:26.867871+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:48:26.868270+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:48:26.869086+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:48:28.356172+0000 | compress | METRIC - time 1.49s\n",
      "2025-09-13T07:48:28.357098+0000 | compress | METRIC - error 3224.71\n",
      "2025-09-13T07:48:28.357850+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:48:28.358417+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:48:28.359061+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:48:29.988897+0000 | compress | METRIC - time 1.63s\n",
      "2025-09-13T07:48:29.989929+0000 | compress | METRIC - error 134822.16\n",
      "2025-09-13T07:48:29.990663+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:48:29.991091+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:48:29.991959+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:48:31.571275+0000 | compress | METRIC - time 1.58s\n",
      "2025-09-13T07:48:31.572282+0000 | compress | METRIC - error 133673.98\n",
      "2025-09-13T07:48:31.573064+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:48:31.573490+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:48:31.574436+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.22.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:48:40.170023+0000 | compress | METRIC - time 8.60s\n",
      "2025-09-13T07:48:40.172481+0000 | compress | METRIC - error 37530.16\n",
      "2025-09-13T07:48:40.173081+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:48:40.173567+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(23/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 183.52it/s]\n",
      "(24/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:49:03.370124+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:49:04.880510+0000 | compress | METRIC - time 1.51s\n",
      "2025-09-13T07:49:04.881564+0000 | compress | METRIC - error 29589.67\n",
      "2025-09-13T07:49:04.882324+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:49:04.882841+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:49:04.883431+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:49:06.305571+0000 | compress | METRIC - time 1.42s\n",
      "2025-09-13T07:49:06.306648+0000 | compress | METRIC - error 4241.69\n",
      "2025-09-13T07:49:06.307195+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:49:06.307680+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:49:06.308566+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:49:07.757461+0000 | compress | METRIC - time 1.45s\n",
      "2025-09-13T07:49:07.758508+0000 | compress | METRIC - error 11055.49\n",
      "2025-09-13T07:49:07.759222+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:49:07.759582+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:49:07.760229+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:49:09.220584+0000 | compress | METRIC - time 1.46s\n",
      "2025-09-13T07:49:09.221614+0000 | compress | METRIC - error 6217.53\n",
      "2025-09-13T07:49:09.222367+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:49:09.222849+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:49:09.223765+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:49:10.793564+0000 | compress | METRIC - time 1.57s\n",
      "2025-09-13T07:49:10.794478+0000 | compress | METRIC - error 174953.03\n",
      "2025-09-13T07:49:10.795343+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:49:10.795746+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:49:10.796635+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:49:12.410615+0000 | compress | METRIC - time 1.61s\n",
      "2025-09-13T07:49:12.411672+0000 | compress | METRIC - error 175947.83\n",
      "2025-09-13T07:49:12.412505+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:49:12.412950+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:49:12.413821+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.23.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:49:21.050682+0000 | compress | METRIC - time 8.64s\n",
      "2025-09-13T07:49:21.053206+0000 | compress | METRIC - error 45734.09\n",
      "2025-09-13T07:49:21.053813+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:49:21.054304+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(24/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 183.12it/s]\n",
      "(25/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:49:44.257003+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:49:45.786649+0000 | compress | METRIC - time 1.53s\n",
      "2025-09-13T07:49:45.787592+0000 | compress | METRIC - error 26418.90\n",
      "2025-09-13T07:49:45.788291+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:49:45.788676+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:49:45.789443+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:49:47.238049+0000 | compress | METRIC - time 1.45s\n",
      "2025-09-13T07:49:47.239103+0000 | compress | METRIC - error 3574.71\n",
      "2025-09-13T07:49:47.239778+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:49:47.240160+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:49:47.240876+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:49:48.653498+0000 | compress | METRIC - time 1.41s\n",
      "2025-09-13T07:49:48.654482+0000 | compress | METRIC - error 11516.51\n",
      "2025-09-13T07:49:48.655233+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:49:48.655643+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:49:48.656403+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:49:50.146376+0000 | compress | METRIC - time 1.49s\n",
      "2025-09-13T07:49:50.147598+0000 | compress | METRIC - error 5751.97\n",
      "2025-09-13T07:49:50.148300+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:49:50.148761+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:49:50.149532+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:49:51.768425+0000 | compress | METRIC - time 1.62s\n",
      "2025-09-13T07:49:51.769488+0000 | compress | METRIC - error 174083.97\n",
      "2025-09-13T07:49:51.769935+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:49:51.770244+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:49:51.771020+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:49:53.418668+0000 | compress | METRIC - time 1.65s\n",
      "2025-09-13T07:49:53.419677+0000 | compress | METRIC - error 189505.47\n",
      "2025-09-13T07:49:53.420390+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:49:53.420891+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:49:53.421597+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.24.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:50:01.817033+0000 | compress | METRIC - time 8.39s\n",
      "2025-09-13T07:50:01.819768+0000 | compress | METRIC - error 59719.40\n",
      "2025-09-13T07:50:01.820389+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:50:01.820804+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(25/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 183.52it/s]\n",
      "(26/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:50:24.901602+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:50:26.431280+0000 | compress | METRIC - time 1.53s\n",
      "2025-09-13T07:50:26.432287+0000 | compress | METRIC - error 27929.86\n",
      "2025-09-13T07:50:26.433079+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:50:26.433487+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:50:26.434285+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:50:27.893432+0000 | compress | METRIC - time 1.46s\n",
      "2025-09-13T07:50:27.894443+0000 | compress | METRIC - error 3455.37\n",
      "2025-09-13T07:50:27.895181+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:50:27.895760+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:50:27.896409+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:50:29.361826+0000 | compress | METRIC - time 1.47s\n",
      "2025-09-13T07:50:29.362880+0000 | compress | METRIC - error 17739.84\n",
      "2025-09-13T07:50:29.363661+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:50:29.364039+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:50:29.364863+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:50:30.818751+0000 | compress | METRIC - time 1.45s\n",
      "2025-09-13T07:50:30.819716+0000 | compress | METRIC - error 8372.61\n",
      "2025-09-13T07:50:30.820453+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:50:30.820847+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:50:30.821659+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:50:32.403414+0000 | compress | METRIC - time 1.58s\n",
      "2025-09-13T07:50:32.404483+0000 | compress | METRIC - error 196806.02\n",
      "2025-09-13T07:50:32.405282+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:50:32.405683+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:50:32.406511+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:50:33.975262+0000 | compress | METRIC - time 1.57s\n",
      "2025-09-13T07:50:33.976269+0000 | compress | METRIC - error 223597.44\n",
      "2025-09-13T07:50:33.977019+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:50:33.977438+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:50:33.978203+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.25.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:50:42.618035+0000 | compress | METRIC - time 8.64s\n",
      "2025-09-13T07:50:42.620585+0000 | compress | METRIC - error 87587.73\n",
      "2025-09-13T07:50:42.621262+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:50:42.621631+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(26/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 184.06it/s]\n",
      "(27/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 24.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:51:05.946176+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:51:07.483944+0000 | compress | METRIC - time 1.54s\n",
      "2025-09-13T07:51:07.485062+0000 | compress | METRIC - error 35148.51\n",
      "2025-09-13T07:51:07.485890+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:51:07.486292+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:51:07.487028+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:51:08.910827+0000 | compress | METRIC - time 1.42s\n",
      "2025-09-13T07:51:08.911780+0000 | compress | METRIC - error 4350.17\n",
      "2025-09-13T07:51:08.912463+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:51:08.912959+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:51:08.913555+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:51:10.345379+0000 | compress | METRIC - time 1.43s\n",
      "2025-09-13T07:51:10.346505+0000 | compress | METRIC - error 32665.17\n",
      "2025-09-13T07:51:10.347226+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:51:10.347615+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:51:10.348345+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:51:11.806110+0000 | compress | METRIC - time 1.46s\n",
      "2025-09-13T07:51:11.807116+0000 | compress | METRIC - error 12224.60\n",
      "2025-09-13T07:51:11.807843+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:51:11.808376+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:51:11.808995+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:51:13.450996+0000 | compress | METRIC - time 1.64s\n",
      "2025-09-13T07:51:13.452019+0000 | compress | METRIC - error 194891.12\n",
      "2025-09-13T07:51:13.452806+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:51:13.453229+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:51:13.453976+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:51:15.069452+0000 | compress | METRIC - time 1.61s\n",
      "2025-09-13T07:51:15.070475+0000 | compress | METRIC - error 223697.58\n",
      "2025-09-13T07:51:15.071157+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:51:15.071508+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:51:15.072199+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.26.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:51:23.503157+0000 | compress | METRIC - time 8.43s\n",
      "2025-09-13T07:51:23.505695+0000 | compress | METRIC - error 254440.08\n",
      "2025-09-13T07:51:23.506414+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:51:23.506745+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(27/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 183.36it/s]\n",
      "(28/29): Calibrating: 100%|██████████| 512/512 [00:20<00:00, 25.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:51:46.576926+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:51:48.126533+0000 | compress | METRIC - time 1.55s\n",
      "2025-09-13T07:51:48.127559+0000 | compress | METRIC - error 47852.18\n",
      "2025-09-13T07:51:48.128311+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:51:48.128711+0000 | compress | METRIC - Compressed module size: 25.998336 MB\n",
      "2025-09-13T07:51:48.129523+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.self_attn.k_proj using 512 samples\n",
      "2025-09-13T07:51:49.598994+0000 | compress | METRIC - time 1.47s\n",
      "2025-09-13T07:51:49.600091+0000 | compress | METRIC - error 5286.56\n",
      "2025-09-13T07:51:49.600903+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:51:49.601292+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:51:49.602141+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.self_attn.v_proj using 512 samples\n",
      "2025-09-13T07:51:51.065393+0000 | compress | METRIC - time 1.46s\n",
      "2025-09-13T07:51:51.066476+0000 | compress | METRIC - error 39865.83\n",
      "2025-09-13T07:51:51.067225+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:51:51.067650+0000 | compress | METRIC - Compressed module size: 3.714048 MB\n",
      "2025-09-13T07:51:51.068434+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.self_attn.o_proj using 512 samples\n",
      "2025-09-13T07:51:52.532430+0000 | compress | METRIC - time 1.46s\n",
      "2025-09-13T07:51:52.533431+0000 | compress | METRIC - error 16475.22\n",
      "2025-09-13T07:51:52.534151+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:51:52.534570+0000 | compress | METRIC - Compressed module size: 25.991168 MB\n",
      "2025-09-13T07:51:52.535323+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.mlp.gate_proj using 512 samples\n",
      "2025-09-13T07:51:54.106825+0000 | compress | METRIC - time 1.57s\n",
      "2025-09-13T07:51:54.107875+0000 | compress | METRIC - error 220649.64\n",
      "2025-09-13T07:51:54.108623+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:51:54.108996+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:51:54.109805+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.mlp.up_proj using 512 samples\n",
      "2025-09-13T07:51:55.726124+0000 | compress | METRIC - time 1.62s\n",
      "2025-09-13T07:51:55.726795+0000 | compress | METRIC - error 231430.75\n",
      "2025-09-13T07:51:55.727605+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:51:55.728153+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n",
      "2025-09-13T07:51:55.728866+0000 | on_sequential_batch_end | INFO - Quantizing model.layers.27.mlp.down_proj using 512 samples\n",
      "2025-09-13T07:52:04.506700+0000 | compress | METRIC - time 8.78s\n",
      "2025-09-13T07:52:04.509292+0000 | compress | METRIC - error 357858.44\n",
      "2025-09-13T07:52:04.509929+0000 | compress | METRIC - GPU 0 | usage: 80.71% | total memory: 48 GB\n",
      "2025-09-13T07:52:04.510291+0000 | compress | METRIC - Compressed module size: 137.381888 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(28/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 183.68it/s]\n",
      "(29/29): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 138.50it/s]\n",
      "(29/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 137.09it/s]\n",
      "manager stage: Modifiers initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:52:14.741983+0000 | initialize | INFO - Compression lifecycle initialized for 1 modifiers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "manager stage: Modifiers finalized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:52:14.743829+0000 | finalize | INFO - Compression lifecycle finalized for 1 modifiers\n",
      "2025-09-13T07:52:14.744280+0000 | post_process | WARNING - Optimized model is not saved. To save, please provide`output_dir` as input arg.Ex. `oneshot(..., output_dir=...)`\n"
     ]
    }
   ],
   "source": [
    "# oneshot modifies model in-place, so reload\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, device_map=\"auto\", torch_dtype=\"auto\"\n",
    ")\n",
    "# run oneshot again, with dataset\n",
    "model = oneshot(\n",
    "    model=model,\n",
    "    dataset=ds,\n",
    "    recipe=recipe,\n",
    "    max_seq_length=max_sequence_length,\n",
    "    num_calibration_samples=num_calibration_samples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:52:14.771475+0000 | save_pretrained_wrapper | INFO - Fetching state_dict - this may take some time\n",
      "2025-09-13T07:52:42.336209+0000 | save_pretrained_wrapper | INFO - Fetching compressor\n",
      "2025-09-13T07:52:42.337006+0000 | get_model_compressor | INFO - skip_sparsity_compression_stats set to True. Skipping sparsity compression statistic calculations. No sparsity compressor will be applied.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Quantized Compression: 100%|██████████| 731/731 [00:40<00:00, 17.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-13T07:53:23.252101+0000 | save_pretrained_wrapper | INFO - Saving compressed model to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Save model and tokenizer\n",
    "model_dir = \"./\" + model_id.split(\"/\")[-1] + \"-GPTQ-W4A16\"\n",
    "model.save_pretrained(model_dir)\n",
    "tokenizer.save_pretrained(model_dir);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4\\) Rerun `lm_eval`\n",
    "\n",
    "Note that perplexity score has improved (lower is better) for this `TinyLlama` model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-09-13 07:53:56] INFO evaluator.py:169: Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\n",
      "[2025-09-13 07:53:56] INFO evaluator.py:193: Initializing vllm model, with arguments: {'pretrained': './Qwen2.5-7B-Instruct-GPTQ-W4A16', 'add_bos_token': True, 'device': 'auto'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-13 07:53:56 [config.py:717] This model supports multiple tasks: {'embed', 'classify', 'score', 'reward', 'generate'}. Defaulting to 'generate'.\n",
      "INFO 09-13 07:53:56 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "INFO 09-13 07:54:00 [__init__.py:239] Automatically detected platform cuda.\n",
      "INFO 09-13 07:54:03 [core.py:58] Initializing a V1 LLM engine (v0.8.5) with config: model='./Qwen2.5-7B-Instruct-GPTQ-W4A16', speculative_config=None, tokenizer='./Qwen2.5-7B-Instruct-GPTQ-W4A16', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=compressed-tensors, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=1234, served_model_name=./Qwen2.5-7B-Instruct-GPTQ-W4A16, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 09-13 07:54:03 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f4326bcfd50>\n",
      "INFO 09-13 07:54:03 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 09-13 07:54:03 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "WARNING 09-13 07:54:03 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 09-13 07:54:03 [gpu_model_runner.py:1329] Starting to load model ./Qwen2.5-7B-Instruct-GPTQ-W4A16...\n",
      "INFO 09-13 07:54:03 [compressed_tensors_wNa16.py:94] Using MarlinLinearKernel for CompressedTensorsWNA16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 1/2 [00:00<00:00,  8.33it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.40it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:00<00:00,  2.69it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-13 07:54:04 [loader.py:458] Loading weights took 0.88 seconds\n",
      "WARNING 09-13 07:54:04 [kv_cache.py:128] Using Q scale 1.0 and prob scale 1.0 with fp8 attention. This may cause accuracy issues. Please make sure Q/prob scaling factors are available in the fp8 checkpoint.\n",
      "INFO 09-13 07:54:05 [gpu_model_runner.py:1347] Model loading took 5.1816 GiB and 1.111515 seconds\n",
      "INFO 09-13 07:54:13 [backends.py:420] Using cache directory: /opt/app-root/src/.cache/vllm/torch_compile_cache/81f807d350/rank_0_0 for vLLM's torch.compile\n",
      "INFO 09-13 07:54:13 [backends.py:430] Dynamo bytecode transform time: 8.42 s\n",
      "INFO 09-13 07:54:16 [backends.py:136] Cache the graph of shape None for later use\n",
      "INFO 09-13 07:54:45 [backends.py:148] Compiling a graph for general shape takes 31.06 s\n",
      "INFO 09-13 07:55:00 [monitor.py:33] torch.compile takes 39.48 s in total\n",
      "INFO 09-13 07:55:01 [kv_cache_utils.py:634] GPU KV cache size: 62,784 tokens\n",
      "INFO 09-13 07:55:01 [kv_cache_utils.py:637] Maximum concurrency for 32,768 tokens per request: 1.92x\n",
      "INFO 09-13 07:55:30 [gpu_model_runner.py:1686] Graph capturing finished in 29 secs, took 0.53 GiB\n",
      "INFO 09-13 07:55:30 [core.py:159] init engine (profile, create kv cache, warmup model) took 85.64 seconds\n",
      "INFO 09-13 07:55:30 [core_client.py:439] Core engine process 0 ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-09-13 07:55:45] INFO task.py:420: Building contexts for gsm8k on rank 0...\n",
      "100%|██████████| 1319/1319 [00:03<00:00, 352.42it/s]\n",
      "[2025-09-13 07:55:49] INFO evaluator.py:517: Running generate_until requests\n",
      "Running generate_until requests:   0%|          | 0/1319 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaeb9881f7ad45b1b9054700ad92fa1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1319 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running generate_until requests: 100%|██████████| 1319/1319 [02:49<00:00,  7.80it/s] \n",
      "[rank0]:[W913 07:58:42.236255874 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    }
   ],
   "source": [
    "results_gptq_w4a16 = lm_eval.simple_evaluate(\n",
    "    model=\"vllm\" if use_gpu else \"hf\",\n",
    "    model_args={\n",
    "        \"pretrained\": model_dir,\n",
    "        \"add_bos_token\": True,\n",
    "        \"device\": \"auto\"\n",
    "    },\n",
    "    tasks=[\"gsm8k\"],\n",
    "    batch_size=\"auto\" if use_gpu else 4,\n",
    "    limit=None if use_gpu else 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Tasks|Version|     Filter     |n-shot|  Metric   |   |Value |   |Stderr|\n",
      "|-----|------:|----------------|-----:|-----------|---|-----:|---|-----:|\n",
      "|gsm8k|      3|flexible-extract|     5|exact_match|↑  |0.7961|±  |0.0111|\n",
      "|     |       |strict-match    |     5|exact_match|↑  |0.7422|±  |0.0120|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(make_table(results_gptq_w4a16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Collect results into a list for easy iteration\n",
    "results_list = [results_baseline, results_w4a16, results_gptq_w4a16]\n",
    "model_names = ['Baseline', 'W4A16', 'GPTQ-W4A16']\n",
    "\n",
    "# Extract the single metric\n",
    "metric_key = \"exact_match,strict-match\"\n",
    "values = [r[\"results\"][\"gsm8k\"][metric_key] for r in results_list]\n",
    "\n",
    "# Convert to numpy array\n",
    "values = np.array(values)\n",
    "\n",
    "# Plot settings\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(model_names, values, color=['#4c72b0', '#55a868', '#c44e52'])\n",
    "\n",
    "# Labels and title\n",
    "plt.ylabel(\"Value (Higher is better)\")\n",
    "plt.xlabel(model_id)\n",
    "plt.title(\"GSM-8K (5-shot, strict-match)\")\n",
    "\n",
    "# Display values on top of each bar\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.02, f\"{yval:.3f}\", ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Model  GSM-8K (5-shot, strict-match)  Recovery (%)\n",
      "  Baseline                          0.809       100.000\n",
      "     W4A16                          0.806        99.625\n",
      "GPTQ-W4A16                          0.742        91.753\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define model names\n",
    "model_names = ['Baseline', 'W4A16', 'GPTQ-W4A16']\n",
    "\n",
    "# Metrics we want to track\n",
    "metrics = [\n",
    "    (\"exact_match,strict-match\", \"GSM-8K (5-shot, strict-match)\"),    \n",
    "]\n",
    "\n",
    "# Extract values for each metric\n",
    "results_list = [results_baseline, results_w4a16, results_gptq_w4a16]\n",
    "\n",
    "# Prepare a dictionary to build the DataFrame\n",
    "data = {\"Model\": model_names}\n",
    "\n",
    "# For each metric, add the raw values and the recovery rates\n",
    "for key, label in metrics:\n",
    "    # Extract raw values\n",
    "    values = [r[\"results\"][\"gsm8k\"][key] for r in results_list]\n",
    "\n",
    "    # Calculate recovery rate relative to baseline\n",
    "    baseline = values[0]\n",
    "    recovery = [\n",
    "        100 if i == 0 else (v / baseline  * 100) for i, v in enumerate(values)\n",
    "    ]\n",
    "    \n",
    "    # Add to table, placing recovery column right next to its metric\n",
    "    data[label] = values\n",
    "    data[f\"Recovery (%)\"] = recovery\n",
    "\n",
    "# Create DataFrame\n",
    "table = pd.DataFrame(data)\n",
    "\n",
    "# Format nicely\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "print(table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
