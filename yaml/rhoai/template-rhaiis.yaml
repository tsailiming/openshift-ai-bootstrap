kind: Template
apiVersion: template.openshift.io/v1
metadata:
  name: template-rhaiis-cuda
  namespace: redhat-ods-applications
  labels:
    opendatahub.io/dashboard: 'true'
  annotations:
    opendatahub.io/apiProtocol: REST
    opendatahub.io/model-type: '["generative"]'
    opendatahub.io/modelServingSupport: '["single"]'    
objects:
  - apiVersion: serving.kserve.io/v1alpha1
    kind: ServingRuntime
    metadata:
      annotations:
        opendatahub.io/recommended-accelerators: '["nvidia.com/gpu"]'
        opendatahub.io/runtime-version: v0.11.2
        openshift.io/display-name: RHAIIS NVIDIA GPU ServingRuntime for KServe
        opendatahub.io/apiProtocol: REST
      labels:
        opendatahub.io/dashboard: 'true'
      name: rhaiis-cuda-runtime
    spec:
      annotations:
        prometheus.io/path: /metrics
        prometheus.io/port: '8080'        
      containers:
        - args:
            - '--port=8080'
            - '--model=/mnt/models'
            - '--served-model-name={{.Name}}'
          command:
            - python
            - '-m'
            - vllm.entrypoints.openai.api_server
          env:
            - name: HF_HOME
              value: /tmp/hf_home
          image: 'registry.redhat.io/rhaiis/vllm-cuda-rhel9:3.2.5'
          name: kserve-container
          ports:
            - containerPort: 8080
              protocol: TCP
      multiModel: false
      supportedModelFormats:
        - autoSelect: true
          name: vLLM
